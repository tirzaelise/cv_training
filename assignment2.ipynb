{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of generative_models.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_cPJipTIgQ-",
        "colab_type": "text"
      },
      "source": [
        "Download the file below to your Google Colab files.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7soeH2ZAIh7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/tirzaelise/cv_training/master/bmnist.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qSCY7ZjIa8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid, save_image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "from bmnist import bmnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJsEHu0tIofp",
        "colab_type": "text"
      },
      "source": [
        "Initialize the GPU with the code below. Make sure that you are running on GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-svfwR2eIpgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEanHcTBIa8d",
        "colab_type": "text"
      },
      "source": [
        "# Part 1. Variational Auto Encoders\n",
        "A VAE is a latent variable model that leverages the flexibility of Neural Networks (NN) in order to learn/specify a latent variable model. We will first briefly discuss Latent Variable Models and then dive into VAEs.\n",
        "\n",
        "## 1.1 Latent Variable Models\n",
        "\n",
        "A latent variable model is a statistical model that contains both\n",
        "observed and unobserved (or latent) variables. Assume a dataset $\\mathcal{D} = \\{x_n\\}^N_{n=1}$, where $x_n \\in \\{0, 1\\}^M$. For example, $x_n$ can be the pixel values of a binary image. The simplest latent variable model for this data can be summarized with the following generative story:\n",
        "\n",
        "$$\n",
        "z_n \\sim \\mathcal{N}(0, I_D) \\\\\n",
        "x_n \\sim p_X(f_\\theta(z_n))\n",
        "$$\n",
        "\n",
        "where $f_\\theta$ is some function — parameterized by $\\theta$ — that maps $z_n$ the parameters of a distribution over $x_n$. For example, if $p_X$ would be a Gaussian distribution, we will use $f_\\theta: \\mathbb{R}^D \\rightarrow (\\mathbb{R}^M, \\mathbb{R}^M_+)$, or if $p_X$ is a product of Bernoulli distributions, we have $f_\\theta: \\mathbb{R}^D \\rightarrow [0,1]^M$. Here, $D$ denotes the dimensionality of the latent space. Note that our dataset $\\mathcal{D}$ does not contain $z_n$, hence $z_n$ is a latent (or unobserved) variable in our statistical model. In the case of a VAE, a (deep) NN is used for $f_\\theta(\\cdot)$.\n",
        "\n",
        "## 1.2 Decoder: Generative part of a VAE\n",
        "\n",
        "In the previous section, a general graphical model for VAEs was given. In this section we will define a more specific generative model that we will use throughout this assignment. This will later be refered to as the decoding part (or decoder) of a VAE. For this assignment\n",
        "we will assume the pixels of our images $x_n$ in $\\mathcal{D}$ are Bernoulli($p$) distributed.\n",
        "\n",
        "$$\n",
        "p(z_n) = \\mathcal{N}(0, I_D) \\\\\n",
        "p(x_n|z_n) = \\prod^M_{m=1} \\text{Bern}(x_n^{(m)}|f_\\theta(z_n)_m)\n",
        "$$\n",
        "\n",
        "where $x_n$ is the $m$th pixel of the $n$th image in $\\mathcal{D}$, and $f_\\theta: \\mathbb{R}^D \\rightarrow [0,1]^M$ is a Neural\n",
        "Network, parameterized by $\\theta$, that outputs the mean of the Bernoulli distributions for each pixel in $x_n$.\n",
        "\n",
        "$p_\\theta(x|z)$ is a multivariate Bernoulli whose probabilities are computed from $z$ with a fully-connected neural network with a single hidden layer:\n",
        "\n",
        "$$\n",
        "\\log p(x|z) = \\sum^D_{i=1} x_i \\log y_i + (1 - x_i) \\cdot \\log (1-y_i) \\\\\n",
        "\\text{where } y = f_\\sigma(W_2 f_{\\text{ReLU}}(W_1z + b_1) + b_2)\n",
        "$$\n",
        "\n",
        "where $f_\\sigma(\\cdot)$ is the elementwise sigmoid activation function, $f_{\\text{ReLU}}$ is the elementwise ReLU activation function, and $\\theta = \\{W_1, W_2, b_1, b_2\\}$ are the weights and biases of the MLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYE_ygDjIa8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_dim=500, z_dim=20):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Perform forward pass of encoder.\n",
        "        Returns mean with shape [batch_size, 784].\n",
        "        \"\"\"\n",
        "        mean = None\n",
        "        raise NotImplementedError()\n",
        "\n",
        "        return mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQmhuSH1Ia8k",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Encoder: $q_\\theta(z_n|x_n)$\n",
        "\n",
        "We only want to sample $z_n$ for which $p(z_n|x_n)$ is not close to zero. One approach is to simply sample from $p(z_n|x_n)$ instead of sampling from $p(z_n)$. However, sampling from (or obtaining an analytical form of) $p(z_n|x_n)$ is intractable in the case of\n",
        "VAE. Instead, we can solve this by sampling from a variational distribution $q(z_n|x_n)$, which we use to approximate the (intractable) posterior $p(z_n|x_n)$. One way to see if two\n",
        "distributions are close to each other is the Kullback-Leibner divergence (KL-divergence):\n",
        "\n",
        "$$\n",
        "D_{\\text{KL}}(q||p) = - \\mathbb{E}_{q(x)} \\Big [ \\log \\frac{p(X)}{q(X)} \\Big ] = - \\int q(x) \\Big [ \\log \\frac{p(x)}{q(x)} \\Big ] dx\n",
        "$$\n",
        "\n",
        "where $q$ and $p$ are probability distributions in the space of some random variable $X$.\n",
        "\n",
        "Now, if we write out the expression for the KL-divergence between our proposal $q(z_n|x_n)$ and our posterior $p(z_n|x_n)$, we can derive an expression for the probability of our data under our model:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "D_{\\text{KL}}(q(Z|x_n)||p(Z|x_n)) &= - \\mathbb{E}_{q(z|x_n)} \\Big [ q(Z|x_n) \\log \\frac{p(Z|x_n)}{q(Z|x_n)} \\Big ] \\\\\n",
        "&= - \\mathbb{E}_{q(z|x_n)} \\Big [ q(Z|x_n) \\log \\frac{p(Z|x_n)p(Z)}{q(Z|x_n)p(x_n)} \\Big ] \\\\\n",
        " &= - \\mathbb{E}_{q(z|x_n)} \\Big [ q(Z|x_n) \\log \\frac{p(Z)}{q(Z|x_n)} + \\log p(x_n|Z) - \\log p(x_n) \\Big ] \\\\\n",
        " &= D_{\\text{KL}}(q(Z|x_n)||p(Z)) - \\mathbb{E}_{q(z|x_n)} [ p(x_n|Z)] + \\log p(x_n) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Hence,\n",
        "\n",
        "$$\\log p(x_n) - D_{\\text{KL}}(q(Z|x_n)||p(Z|x_n)) = \\mathbb{E}_{q(z|x_n)} [ p(x_n|Z)] - D_{\\text{KL}}(q(Z|x_n)||p(Z)) $$\n",
        "\n",
        "We have arranged the equation above so that directly-computable quantities are on the right-hand side. The right side of the equation is referred to as the lower bound on the log-probability of the data. This is what will optimize. We define our loss as the mean negative lower bound:\n",
        "\n",
        "$$\\mathcal{L}(\\theta, \\phi) = -\\frac{1}{N} \\sum^N_{n=1} \\mathbb{E}_{q_\\phi(z|x_n)} [p_\\theta(x_n|Z) - D_{\\text{KL}}(q_\\phi(Z|x_n) || p_\\theta(Z))$$\n",
        "\n",
        "## 1.4 Specifying the encoder\n",
        "\n",
        "In VAEs, we have some freedom to choose the distribution $q_\\phi(z_n|x_n)$. In essence we want to choose something that can closely approximate $p(z_n|x_n)$, but we are also free a select\n",
        "distribution that makes our life easier. We will do exactly that in this case and choose $q_\\phi(z_n|x_n)$ to be a factored multivariate normal distribution, i.e.,\n",
        "\n",
        "$$q_\\phi(z_n|x_n) = \\mathcal{N}(z_n|\\mu_\\phi(x_n), \\text{diag}(\\Sigma_\\phi(x_n))),$$\n",
        "\n",
        "where $\\mu_\\phi: \\mathbb{R}^M \\rightarrow \\mathbb{R}^D$ maps an input image to the mean of the multivariate normal over $z_n$ and $\\Sigma_\\phi: \\mathbb{R}^D \\rightarrow \\mathbb{R}^M_{>0}$ maps the input image to the diagonal of the covariance matrix of that same distribution. Moreover, diag($v$) maps a $K$-dimensional (for any $K$) input vector $v$ to a $K \\times K$ matrix such that for $i,j \\in \\{1, ..., K\\}$:\n",
        "\n",
        "$$\n",
        "\\text{diag}(v)_{ij} = \n",
        "\\begin{cases} \n",
        "   v_i & \\text{if } i = j \\\\\n",
        "   0   & \\text{if } \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The encoder is a multivariate Gaussian with a diagonal covariance structure:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\log q_\\phi(z|x) &= \\log \\mathcal{N}(z; \\mu, \\sigma^2I) \\\\\n",
        "\\text{where } \\mu &= W_4h+b_4 \\\\\n",
        "\\log \\sigma^2 &= W_5h + b_5 \\\\\n",
        "h &= f_{\\text{ReLU}}(W_3 x + b_3)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "where $\\{W_3, W_4, W_5, b_3, b_4, b_5\\}$ are the weights and biases of the MLP and $f_{\\text{ReLU}}$ is the elementwise ReLU activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6-SB-oWIa8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_dim=500, z_dim=20):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Perform forward pass of encoder.\n",
        "        Returns mean and std with shape [batch_size, z_dim]. Make sure\n",
        "        that any constraints are enforced.\n",
        "        \"\"\"\n",
        "        mean, std = None, None\n",
        "        raise NotImplementedError()\n",
        "\n",
        "        return mean, std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7gEK6jLIvVf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWQwRGieIa8t",
        "colab_type": "text"
      },
      "source": [
        "## 1.6 Building a VAE\n",
        "\n",
        "We can now implement a VAE in Pytorch. You may assume that the number of samples used to approximate the expectation in the loss is 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QmCC9vKIa8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_dim=500, z_dim=20):\n",
        "        super().__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.encoder = Encoder(hidden_dim, z_dim)\n",
        "        self.decoder = Decoder(hidden_dim, z_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Given input, perform an encoding and decoding step and return the\n",
        "        negative average elbo for the given batch.\n",
        "        \"\"\"\n",
        "        average_negative_elbo = None\n",
        "        raise NotImplementedError()\n",
        "        return average_negative_elbo\n",
        "\n",
        "    def sample(self, n_samples):\n",
        "        \"\"\"\n",
        "        Sample n_samples from the model. Return both the sampled images\n",
        "        (from bernoulli) and the means for these bernoullis (as these are\n",
        "        used to plot the data manifold).\n",
        "        \"\"\"\n",
        "        sampled_ims, im_means = None, None\n",
        "        raise NotImplementedError()\n",
        "\n",
        "        return sampled_ims, im_means\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoLYymbLIa80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_iter(model, data, optimizer):\n",
        "    \"\"\"\n",
        "    Perform a single epoch for either the training or validation.\n",
        "    use model.training to determine if in 'training mode' or not.\n",
        "    Returns the average elbo for the complete epoch.\n",
        "    \"\"\"\n",
        "    average_epoch_elbo = None\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    return average_epoch_elbo\n",
        "\n",
        "\n",
        "def run_epoch(model, data, optimizer):\n",
        "    \"\"\"\n",
        "    Run a train and validation epoch and return average elbo for each.\n",
        "    \"\"\"\n",
        "    traindata, valdata = data\n",
        "\n",
        "    model.train()\n",
        "    train_elbo = epoch_iter(model, traindata, optimizer)\n",
        "\n",
        "    model.eval()\n",
        "    val_elbo = epoch_iter(model, valdata, optimizer)\n",
        "\n",
        "    return train_elbo, val_elbo\n",
        "\n",
        "\n",
        "def save_elbo_plot(train_curve, val_curve, filename):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_curve, label='train elbo')\n",
        "    plt.plot(val_curve, label='validation elbo')\n",
        "    plt.legend()\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('ELBO')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqunEpZyIa85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vae_main(epochs, zdim):\n",
        "    data = bmnist()[:2]  # ignore test split\n",
        "    model = VAE(z_dim=zdim)\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    train_curve, val_curve = [], []\n",
        "    for epoch in range(epochs):\n",
        "        elbos = run_epoch(model, data, optimizer)\n",
        "        train_elbo, val_elbo = elbos\n",
        "        train_curve.append(train_elbo)\n",
        "        val_curve.append(val_elbo)\n",
        "        print(f\"[Epoch {epoch}] train elbo: {train_elbo} val_elbo: {val_elbo}\")\n",
        "\n",
        "        # --------------------------------------------------------------------\n",
        "        #  Add functionality to plot samples from model during training.\n",
        "        #  You can use the make_grid functioanlity that is already imported.\n",
        "        # --------------------------------------------------------------------\n",
        "\n",
        "    save_elbo_plot(train_curve, val_curve, 'elbo.pdf')\n",
        "\n",
        "epochs = 40\n",
        "zdim = 20\n",
        "vae_main(epochs, zdim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmCiIf6XIa8-",
        "colab_type": "text"
      },
      "source": [
        "Plot the estimated lower-bounds of your training and validation set as training progresses — using a 20-dimensional latent space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA5q01V6Ia8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bki388GlIa9D",
        "colab_type": "text"
      },
      "source": [
        "Plot samples from your model at three points throughout training (before training, half way through training, and after training). You should observe an improvement in the quality of samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_x8hmp1Ia9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFk-aTUAIa9K",
        "colab_type": "text"
      },
      "source": [
        "# Part 2. Generative Adversarial Networks\n",
        "\n",
        "Generative Adversarial Networks (GAN) are a type of deep generative models. Similar to VAEs, GANs can generate images that mimick images from the dataset by sampling an encoding from a noise distribution. In constract to VAEs, in vanilla GANs there is no inference mechanism to determine an encoding or latent vector that corresponds to a given data point (or image). One thing to notice is that a GAN consists of two separate networks (i.e., there is no parameter sharing, or the like) called the generator and the discriminator. Training a GAN leverages am adversarial training scheme. In short, that means that instead of defining a loss function by hand (e.g., cross entropy or mean squared error), we train a network that acts as a loss function. In the case of a GAN this network is trained to discriminate between real images and fake (or generated) images, hence the name iscriminator. The discriminator (together with the training data) then serves as a loss function for our generator network that will learn to generate images to are similar to those in the training set. Both the generator and discriminator are trained jointly. In this assignment we will focus on obtaining a generator network that can generate images that are similar to those in the training set.\n",
        "\n",
        "## 2.1 Training objective: A Minimax Game\n",
        "\n",
        "In order to train a GAN we have to decide on a noise distribution $p(z)$, in this case we will use a standard Normal distribution. Given this noise distribution, the GAN training procedure is a minimax game between the generator and discriminator. This is best seen by inspecting the loss (or optimization objective):\n",
        "\n",
        "$$\\min_G \\max_D V(D,G) = \\min_G \\max_D \\mathbb{E}_{p_{\\text{data}}(x)} [\\log D(X)] + \\mathbb{E}_{p_z(z)}[\\log (1-D(G(Z)))]$$\n",
        "\n",
        "## 2.2 Building a GAN\n",
        "\n",
        "Now that the objective is specified and it is clear how the generator and discriminator should behave, we are ready to implement a GAN. In this part of the assignment you will implement a GAN in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8blzP0jIa9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Construct generator. You are free to experiment with your model,\n",
        "        # but the following is a good start:\n",
        "        #   Linear latent_dim -> 128\n",
        "        #   LeakyReLU(0.2)\n",
        "        #   Linear 128 -> 256\n",
        "        #   Bnorm\n",
        "        #   LeakyReLU(0.2)\n",
        "        #   Linear 256 -> 512\n",
        "        #   Bnorm\n",
        "        #   LeakyReLU(0.2)\n",
        "        #   Linear 512 -> 1024\n",
        "        #   Bnorm\n",
        "        #   LeakyReLU(0.2)\n",
        "        #   Linear 1024 -> 768\n",
        "        #   Output non-linearity\n",
        "\n",
        "    def forward(self, z):\n",
        "        # Generate images from z\n",
        "        pass\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Construct distriminator. You are free to experiment with your model,\n",
        "        # but the following is a good start:\n",
        "        #   Linear 784 -> 512\n",
        "        #   LeakyReLU(0.2)\n",
        "        #   Linear 512 -> 256\n",
        "        #   LeakyReLU(0.2)\n",
        "        #   Linear 256 -> 1\n",
        "        #   Output non-linearity\n",
        "\n",
        "    def forward(self, img):\n",
        "        # return discriminator score for img\n",
        "        pass\n",
        "\n",
        "\n",
        "def train_gan(dataloader, discriminator, generator, optimizer_G, optimizer_D, n_epochs, save_interval):\n",
        "    for epoch in range(n_epochs):\n",
        "        for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "            imgs.cuda()\n",
        "\n",
        "            # Train Generator\n",
        "            # ---------------\n",
        "\n",
        "            # Train Discriminator\n",
        "            # -------------------\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Save Images\n",
        "            # -----------\n",
        "            batches_done = epoch * len(dataloader) + i\n",
        "            if batches_done % save_interval == 0:\n",
        "                # You can use the function save_image(Tensor (shape Bx1x28x28),\n",
        "                # filename, number of rows, normalize) to save the generated\n",
        "                # images, e.g.:\n",
        "                # save_image(gen_imgs[:25],\n",
        "                #            'images/{}.png'.format(batches_done),\n",
        "                #            nrow=5, normalize=True)\n",
        "                pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76PeQIulIa9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gan_main(n_epochs, batch_size, lr, latent_dim, save_interval):\n",
        "    # Create output image directory\n",
        "    os.makedirs('images', exist_ok=True)\n",
        "\n",
        "    # load data\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('./data/mnist', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.5,),\n",
        "                                                (0.5,))])),\n",
        "        batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize models and optimizers\n",
        "    generator = Generator()\n",
        "    discriminator = Discriminator()\n",
        "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "    # Start training\n",
        "    train_gan(dataloader, discriminator, generator, optimizer_G, optimizer_D, n_epochs, save_interval)\n",
        "\n",
        "    # You can save your generator here to re-use it to generate images for your\n",
        "    # report, e.g.:\n",
        "    # torch.save(generator.state_dict(), \"mnist_generator.pt\")\n",
        "\n",
        "n_epochs = 200\n",
        "batch_size = 64\n",
        "lr = 0.0002\n",
        "latent_dim = 100\n",
        "save_interval = 500\n",
        "gan_main(n_epochs, batch_size, lr, latent_dim, save_interval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e0x4aLAIa9X",
        "colab_type": "text"
      },
      "source": [
        "Sample 25 images from your trained GAN. Do this at the start of training, halfway through training and after training has terminated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_usYS_n_Ia9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHcbQ1nkIa9d",
        "colab_type": "text"
      },
      "source": [
        "Edit the architecture of your GAN until you feel that you are getting good images."
      ]
    }
  ]
}