{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOW_Y862T60E",
        "colab_type": "text"
      },
      "source": [
        "# Implementing your own CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZv0NTmCT60G",
        "colab_type": "text"
      },
      "source": [
        "## Part I. Preparation\n",
        "\n",
        "First, we load the CIFAR-10 dataset. This might take a couple minutes the first time you do it, but the files should stay cached after that. PyTorch provides convenient tools to download, preprocess and iterate through our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqemhltrT60I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7905V2vfT60P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_TRAIN = 49000\n",
        "\n",
        "# The torchvision.transforms package provides tools for preprocessing data\n",
        "# and for performing data augmentation; here we set up a transform to\n",
        "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
        "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])\n",
        "\n",
        "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
        "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
        "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
        "# training set into train and val sets by passing a Sampler object to the\n",
        "# DataLoader telling how it should sample from the underlying Dataset.\n",
        "cifar10_train = datasets.CIFAR10('cifar10', train=True, download=True,\n",
        "                             transform=transform)\n",
        "loader_train = DataLoader(cifar10_train, batch_size=16, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "cifar10_val = datasets.CIFAR10('cifar10', train=True, download=True,\n",
        "                           transform=transform)\n",
        "loader_val = DataLoader(cifar10_val, batch_size=16, \n",
        "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "cifar10_test = datasets.CIFAR10('cifar10', train=False, download=True, \n",
        "                            transform=transform)\n",
        "loader_test = DataLoader(cifar10_test, batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Y6m6rMT60V",
        "colab_type": "text"
      },
      "source": [
        "You have an option to **use GPU by setting the flag to True below**. If you do not have CUDA enabled, `torch.cuda.is_available()` will return False and this notebook will fallback to CPU mode.\n",
        "\n",
        "The global variables `dtype` and `device` will control the data types throughout this assignment. **Make sure you are using Google Colab correctly (GPU) by checking the printed device.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiAki3ydT60X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_GPU = True\n",
        "\n",
        "dtype = torch.float32 # we will be using float throughout this assignment\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 100\n",
        "\n",
        "print('using device:', device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT6GF1i3T60d",
        "colab_type": "text"
      },
      "source": [
        "## Part II. PyTorch Module API\n",
        "\n",
        "PyTorch provides the `nn.Module` API for you to define arbitrary network architectures, while tracking every learnable parameters for you. PyTorch provides the `torch.optim` package that implements all the common optimizers, such as RMSProp, Adagrad, and Adam. It even supports approximate second-order methods like L-BFGS! You can refer to the [doc](http://pytorch.org/docs/master/optim.html) for the exact specifications of each optimizer.\n",
        "\n",
        "To use the Module API, follow the steps below:\n",
        "\n",
        "1. Subclass `nn.Module`. Give your network class an intuitive name like `TwoLayerFC`. \n",
        "\n",
        "2. In the constructor `__init__()`, define all the layers you need as class attributes. Layer objects like `nn.Linear` and `nn.Conv2d` are themselves `nn.Module` subclasses and contain learnable parameters, so that you don't have to instantiate the raw tensors yourself. `nn.Module` will track these internal parameters for you. Refer to the [doc](http://pytorch.org/docs/master/nn.html) to learn more about the dozens of builtin layers. **Warning**: don't forget to call the `super().__init__()` first!\n",
        "\n",
        "3. In the `forward()` method, define the *connectivity* of your network. You should use the attributes defined in `__init__` as function calls that take tensor as input and output the \"transformed\" tensor. Do *not* create any new layers with learnable parameters in `forward()`! All of them must be declared upfront in `__init__`. \n",
        "\n",
        "After you define your Module subclass, you can instantiate it as an object and call it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWBdu_OfT60f",
        "colab_type": "text"
      },
      "source": [
        "### Architecture\n",
        "\n",
        "Implement your own CNN with the architecture described in the table below  (https://pytorch.org/docs/stable/nn.html).  <br>\n",
        "<br>\n",
        "\n",
        "| Name     | Kernel | Padding | Channels In/Out |\n",
        "|:---------|:-------|:--------|:----------------|\n",
        "| conv1    | 5x5    | 2       | 3/32            |\n",
        "| relu     | -      | -       | 32/32           |\n",
        "| maxpool1 | 4x4    | 0       | 32/32           |\n",
        "| conv2    | 3x3    | 1       | 32/64           |\n",
        "| relu     | -      | -       | 64/64           |\n",
        "| maxpool2 | 4x4    | -       | 64/64           | \n",
        "| avgpool  | 2x2    | -       | 64/64           |\n",
        "| linear   | -      | -       | 64/10           |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-mrUNA9T60g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, in_channel, num_classes):\n",
        "        super().__init__()\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "def test_ConvNet():\n",
        "    x = torch.zeros((batch_size, 3, 32, 32), dtype=dtype)  # minibatch $batch_size, image size [3, 32, 32]\n",
        "    model = ConvNet(in_channel=3, num_classes=10)\n",
        "    scores = model(x)\n",
        "    print(scores.size())  # you should see [batch_size, 10]\n",
        "    \n",
        "test_ConvNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz05hcc5T60m",
        "colab_type": "text"
      },
      "source": [
        "### Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvHRx4SCT60p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loss_fn, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - loss_fn: A PyTorch Module giving the loss function that is used to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    \n",
        "    raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg1gQqYbT60w",
        "colab_type": "text"
      },
      "source": [
        "### Check Accuracy\n",
        "Given the validation or test set, we can check the classification accuracy of a neural network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKEV7In4T60x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_accuracy(loader, model):\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY0q5yibT602",
        "colab_type": "text"
      },
      "source": [
        "## Part III. CIFAR-10 Challenge\n",
        "\n",
        "In this section, you can experiment with whatever ConvNet architecture you'd like on CIFAR-10.\n",
        "\n",
        "Now it's your job to experiment with architectures, hyperparameters, loss functions, and optimizers to train a model that achieves at least 70% accuracy on the CIFAR-10 validation set within 10 epochs. You can use the check_accuracy and train functions from above. \n",
        "\n",
        "* Layers in torch.nn package: http://pytorch.org/docs/stable/nn.html\n",
        "* Activations: http://pytorch.org/docs/stable/nn.html#non-linear-activations\n",
        "* Loss functions: http://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "* Optimizers: http://pytorch.org/docs/stable/optim.html\n",
        "* Data augmentation: https://pytorch.org/docs/stable/torchvision/transforms.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0JFWwdnT606",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Experiment with any architectures, optimizers, and hyperparameters.          \n",
        "# Achieve AT LEAST 70% accuracy on the *validation set* within 10 epochs.      \n",
        "#                                                                              \n",
        "# Note that you can use the check_accuracy function to evaluate on either      \n",
        "# the test set or the validation set, by passing either loader_test or         \n",
        "# loader_val as the second argument to check_accuracy. You should not touch    \n",
        "# the test set until you have finished your architecture and  hyperparameter   \n",
        "# tuning, and only run the test set once at the end to report a final value.   \n",
        "\n",
        "\n",
        "model = None\n",
        "loss_fn = None\n",
        "optimizer = None\n",
        "\n",
        "train(model, loss_fn, optimizer, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvxveSrxT60_",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.\n",
        "\n",
        "* **Finetuning the convnet:** Instead of random initializaion, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. Rest of the training looks as usual.\n",
        "* **ConvNet as fixed feature extractor:** Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained.\n",
        "\n",
        "We're going to train a model to classify ants and bees. We have about 120 training images each for ants and bees. There are 75 validation images for each class. Usually, this is a very small dataset to generalize upon, if trained from scratch. Since we are using transfer learning, we should be able to generalize reasonably well.\n",
        "\n",
        "This dataset is a very small subset of imagenet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdIAn2t7T61A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24rJqrMfVg7Q",
        "colab_type": "text"
      },
      "source": [
        "Download and unzip the images first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joZ-Kbv7Vh-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/tirzaelise/cv_training/blob/master/ants_bees.zip?raw=true\n",
        "!unzip ants_bees.zip?raw=true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wCi22hfT61F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'ants_bees'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36koXuqTT61J",
        "colab_type": "text"
      },
      "source": [
        "## Visualize Transformations\n",
        "\n",
        "We will visualize a few images to understand the data augmentations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjl_bJbRT61L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En2Zfn7GT61Q",
        "colab_type": "text"
      },
      "source": [
        "## Finetuning the ConvNet\n",
        "\n",
        "To train the model, we will keep track of the model's accuracy during the training phase. Every epoch will consist of a training and validation set, where we will begin by setting the model's best weights to those of the pretrained mode. If we move to the validation phase and the accuracy has improved, we will save the current weights as the best model weights. Remember that the weights should only be updated when the model is training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4BPf-NaT61S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTmNL2DbT61W",
        "colab_type": "text"
      },
      "source": [
        "Load a pretrained model and reset the final fully connected layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZTeA4E-T61Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0XuwClAT61e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtFdcD9hT61j",
        "colab_type": "text"
      },
      "source": [
        "## ConvNet as fixed feature extractor\n",
        "\n",
        "Due to long training times, people sometimes choose to only train the last layer, while keeping the pretrained model as a fixed feature extractor. Thus, we need to freeze all of the network except the final layer. We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward(). Parameters of newly constructured modules also have requires_grad=True by default.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV7zWPg_T61k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "## YOUR CODE HERE\n",
        "\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eHiqtCBT61o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}